{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-12-21T14:42:28.897988Z",
     "iopub.status.busy": "2024-12-21T14:42:28.897771Z",
     "iopub.status.idle": "2024-12-21T14:42:41.414017Z",
     "shell.execute_reply": "2024-12-21T14:42:41.412953Z",
     "shell.execute_reply.started": "2024-12-21T14:42:28.897961Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.52-py3-none-any.whl.metadata (35 kB)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (10.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.4.1+cu121)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.19.1+cu121)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.5)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.4)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Downloading ultralytics_thop-2.0.13-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Downloading ultralytics-8.3.52-py3-none-any.whl (901 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m901.7/901.7 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ultralytics_thop-2.0.13-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: ultralytics-thop, ultralytics\n",
      "Successfully installed ultralytics-8.3.52 ultralytics-thop-2.0.13\n",
      "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
      "Collecting moviepy\n",
      "  Downloading moviepy-2.1.1-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: decorator<6.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.35.1)\n",
      "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.5.1)\n",
      "Requirement already satisfied: numpy>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.26.4)\n",
      "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
      "Collecting python-dotenv>=0.10 (from moviepy)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: pillow<11.0,>=9.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (10.4.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio_ffmpeg>=0.2.0->moviepy) (71.0.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from proglog<=1.0.0->moviepy) (4.66.5)\n",
      "Downloading moviepy-2.1.1-py3-none-any.whl (123 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.5/123.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv, moviepy\n",
      "  Attempting uninstall: moviepy\n",
      "    Found existing installation: moviepy 1.0.3\n",
      "    Uninstalling moviepy-1.0.3:\n",
      "      Successfully uninstalled moviepy-1.0.3\n",
      "Successfully installed moviepy-2.1.1 python-dotenv-1.0.1\n",
      "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.16.1)\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.8.30)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics\n",
    "!pip install moviepy --upgrade\n",
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T14:42:41.415353Z",
     "iopub.status.busy": "2024-12-21T14:42:41.415135Z",
     "iopub.status.idle": "2024-12-21T14:42:46.939606Z",
     "shell.execute_reply": "2024-12-21T14:42:46.938715Z",
     "shell.execute_reply.started": "2024-12-21T14:42:41.415336Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Tuple, Sequence\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import unravel_index\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from tqdm import tqdm, notebook\n",
    "from ultralytics import YOLO\n",
    "\n",
    "from moviepy.video.io.ImageSequenceClip import ImageSequenceClip\n",
    "\n",
    "import math\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "import random\n",
    "import csv\n",
    "import yaml\n",
    "import gdown\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T14:42:46.940764Z",
     "iopub.status.busy": "2024-12-21T14:42:46.940408Z",
     "iopub.status.idle": "2024-12-21T14:42:46.950635Z",
     "shell.execute_reply": "2024-12-21T14:42:46.949832Z",
     "shell.execute_reply.started": "2024-12-21T14:42:46.940723Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_num_clips(path: Path, game: int) -> int:\n",
    "    return len(list((path / f'game{game}/').iterdir()))\n",
    "\n",
    "\n",
    "def get_game_clip_pairs(path: Path, games: List[int]) -> List[Tuple[int, int]]:\n",
    "    return [(game, c)  for game in games for c in range(1, get_num_clips(path, game) + 1)]\n",
    "\n",
    "\n",
    "def load_clip_data(path: Path, game: int, clip: int, downscale: bool, quiet=False) -> np.ndarray:\n",
    "    if not quiet:\n",
    "        suffix = 'downscaled' if downscale else ''\n",
    "        print(f'loading clip data (game {game}, clip {clip}) {suffix}')\n",
    "    cache_path = path / 'cache'\n",
    "    cache_path.mkdir(exist_ok=True)\n",
    "    resize_code = '_ds2' if downscale else ''\n",
    "    cached_data_name = f'{game}_{clip}{resize_code}.npz'\n",
    "    if (cache_path / cached_data_name).exists():\n",
    "        clip_data = np.load(cache_path / cached_data_name)['clip_data']\n",
    "    else:\n",
    "        clip_path = path / f'game{game}/clip{clip}'\n",
    "        n_imgs = len(list(clip_path.iterdir())) - 1\n",
    "        imgs = [None] * n_imgs\n",
    "        for i in notebook.tqdm(range(n_imgs)):\n",
    "            img = Image.open(clip_path / f'{i:04d}.jpg')\n",
    "            if downscale:\n",
    "                img = img.resize((img.width // 2, img.height // 2),)\n",
    "            imgs[i] = np.array(img, dtype=np.uint8)\n",
    "        clip_data = np.stack(imgs)\n",
    "        cache_path.mkdir(exist_ok=True, parents=True)\n",
    "        np.savez_compressed(cache_path / cached_data_name, clip_data=clip_data)\n",
    "    return clip_data\n",
    "\n",
    "\n",
    "def load_clip_labels(path: Path, game: int, clip: int, downscale: bool, quiet=False):\n",
    "    if not quiet:\n",
    "        print(f'loading clip labels (game {game}, clip {clip})')\n",
    "    clip_path = path / f'game{game}/clip{clip}'\n",
    "    labels = []\n",
    "    with open(clip_path / 'labels.csv') as csvfile:\n",
    "        lines = list(csv.reader(csvfile))\n",
    "        for line in lines[1:]:\n",
    "            values = np.array([-1 if i == '' else int(i) for i in line[1:]])\n",
    "            if downscale:\n",
    "                values[1] //= 2\n",
    "                values[2] //= 2\n",
    "            labels.append(values)\n",
    "    return np.stack(labels)\n",
    "\n",
    "\n",
    "def load_clip(path: Path, game: int, clip: int, downscale: bool, quiet=False):\n",
    "    data = load_clip_data(path, game, clip, downscale, quiet)\n",
    "    labels = load_clip_labels(path, game, clip, downscale, quiet)\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T14:42:46.954336Z",
     "iopub.status.busy": "2024-12-21T14:42:46.954122Z",
     "iopub.status.idle": "2024-12-21T14:42:46.965946Z",
     "shell.execute_reply": "2024-12-21T14:42:46.964812Z",
     "shell.execute_reply.started": "2024-12-21T14:42:46.954316Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prepare_experiment(out_path: Path) -> Path:\n",
    "    out_path.mkdir(parents=True, exist_ok=True)\n",
    "    dirs = [d for d in out_path.iterdir() if d.is_dir() and d.name.startswith('exp_')]\n",
    "    experiment_id = max(int(d.name.split('_')[1]) for d in dirs) + 1 if dirs else 1\n",
    "    exp_path = out_path / f'exp_{experiment_id}'\n",
    "    exp_path.mkdir()\n",
    "    return exp_path\n",
    "\n",
    "\n",
    "def ball_gauss_template(rad, sigma):\n",
    "    x, y = np.meshgrid(np.linspace(-rad, rad, 2 * rad + 1), np.linspace(-rad, rad, 2 * rad + 1)) \n",
    "    dst = np.sqrt(x * x + y * y) \n",
    "    gauss = np.exp(-(dst ** 2 / (2.0 * sigma ** 2)))     \n",
    "    return gauss\n",
    "\n",
    "\n",
    "def create_masks(data: np.ndarray, labels: np.ndarray, resize):\n",
    "    rad = 64 #25\n",
    "    sigma = 10\n",
    "    if resize:\n",
    "        rad //= 2\n",
    "    ball = ball_gauss_template(rad, sigma)\n",
    "    n_frames = data.shape[0]\n",
    "    sh = rad\n",
    "    masks = []\n",
    "    for i in range(n_frames):\n",
    "        label = labels[i, ...] \n",
    "        frame = data[i, ...]\n",
    "        if 0 < label[0] < 3:\n",
    "            x, y = label[1:3]\n",
    "            mask = np.zeros((frame.shape[0] + 2 * rad + 2 * sh, frame.shape[1] + 2 * rad + 2 * sh), np.float32)\n",
    "            mask[y + sh : y + sh + 2 * rad + 1, x + sh : x + sh + 2 * rad + 1] = ball\n",
    "            mask = mask[rad + sh : -rad - sh, rad + sh : -rad - sh]\n",
    "            masks.append(mask)\n",
    "        else:\n",
    "            masks.append(np.zeros((frame.shape[0], frame.shape[1]), dtype=np.float32))\n",
    "    return np.stack(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T14:42:46.967269Z",
     "iopub.status.busy": "2024-12-21T14:42:46.966963Z",
     "iopub.status.idle": "2024-12-21T14:42:46.982473Z",
     "shell.execute_reply": "2024-12-21T14:42:46.981719Z",
     "shell.execute_reply.started": "2024-12-21T14:42:46.967228Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def _add_frame_number(frame: np.ndarray, number: int) -> np.ndarray:\n",
    "    fnt = ImageFont.load_default() # ImageFont.truetype(\"arial.ttf\", 25)\n",
    "    img = Image.fromarray(frame)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    draw.text((10, 10), f'frame {number}', font=fnt, fill=(255, 0, 255))\n",
    "    return np.array(img)\n",
    "\n",
    "\n",
    "def _vis_clip(data: np.ndarray, lbls: np.ndarray, metrics: List[float] = None, ball_rad=5, color=(255, 0, 0), track_length=10):\n",
    "    print('perfoming clip visualization')\n",
    "    n_frames = data.shape[0]\n",
    "    frames_res = []\n",
    "    fnt = ImageFont.load_default() # ImageFont.truetype(\"arial.ttf\", 25)\n",
    "    for i in range(n_frames):\n",
    "        img = Image.fromarray(data[i, ...])\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        txt = f'frame {i}'\n",
    "        if metrics is not None:\n",
    "            txt += f', SiBaTrAcc: {metrics[i]:.3f}'\n",
    "        draw.text((10, 10), txt, font=fnt, fill=(255, 0, 255))\n",
    "        label = lbls[i]\n",
    "        if label[0] != 0: # the ball is clearly visible\n",
    "            px, py = label[1], label[2]\n",
    "            draw.ellipse((px - ball_rad, py - ball_rad, px + ball_rad, py + ball_rad), outline=color, width=2)\n",
    "            for q in range(track_length):\n",
    "                if lbls[i-q-1][0] == 0:\n",
    "                    break\n",
    "                if i - q > 0:\n",
    "                    draw.line((lbls[i - q - 1][1], lbls[i - q - 1][2], lbls[i - q][1], lbls[i - q][2]), fill=color)                \n",
    "        frames_res.append(np.array(img))\n",
    "    return frames_res\n",
    "\n",
    "\n",
    "def _save_clip(frames: Sequence[np.ndarray], path: Path, fps):\n",
    "    assert path.suffix in ('.mp4', '.gif')\n",
    "    clip = ImageSequenceClip(frames, fps=fps)\n",
    "    if path.suffix == '.mp4':\n",
    "        clip.write_videofile(str(path), fps=fps, logger=None)\n",
    "    else:\n",
    "        clip.write_gif(str(path), fps=fps, logger=None)\n",
    "\n",
    "\n",
    "def _to_yellow_heatmap(frame: np.ndarray, pred_frame: np.ndarray, alpha=0.4):\n",
    "    img = Image.fromarray((frame * alpha).astype(np.uint8))\n",
    "    maskR = (pred_frame * (1 - alpha) * 255).astype(np.uint8)\n",
    "    maskG = (pred_frame * (1 - alpha) * 255).astype(np.uint8)\n",
    "    maskB = np.zeros_like(maskG, dtype=np.uint8)\n",
    "    mask = np.stack([maskR, maskG, maskB], axis=-1)\n",
    "    return img + mask\n",
    "\n",
    "\n",
    "def _vis_pred_heatmap(data_full: np.ndarray, pred_prob: np.ndarray, display_frame_number):\n",
    "    n_frames = data_full.shape[0]\n",
    "    v_frames = []\n",
    "    for i in range(n_frames):\n",
    "        frame = data_full[i, ...]\n",
    "        pred = pred_prob[i, ...]\n",
    "        hm = _to_yellow_heatmap(frame, pred)\n",
    "        if display_frame_number:\n",
    "            hm = _add_frame_number(hm, i)\n",
    "        v_frames.append(hm)\n",
    "    return v_frames\n",
    "\n",
    "\n",
    "def visualize_prediction(data_full: np.ndarray, labels_pr: np.ndarray, save_path: Path, name: str, metrics=None, fps=15):\n",
    "    with open(save_path / f'{name}.txt', mode='w') as f:\n",
    "        if metrics is not None:\n",
    "            f.write(f'SiBaTrAcc: {metrics[-1]} \\n')\n",
    "        for i in range(labels_pr.shape[0]):\n",
    "            f.write(f'frame {i}: {labels_pr[i, 0]}, {labels_pr[i, 1]}, {labels_pr[i, 2]} \\n')\n",
    "\n",
    "    v = _vis_clip(data_full, labels_pr, metrics)\n",
    "    _save_clip(v, save_path / f'{name}.mp4', fps=fps)\n",
    "\n",
    "\n",
    "def visualize_prob(data: np.ndarray, pred_prob: np.ndarray, save_path: Path, name: str, frame_number=True, fps=15):\n",
    "    v_pred = _vis_pred_heatmap(data, pred_prob, frame_number)\n",
    "    _save_clip(v_pred, save_path / f'{name}_prob.mp4', fps=fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T14:42:52.016191Z",
     "iopub.status.busy": "2024-12-21T14:42:52.015881Z",
     "iopub.status.idle": "2024-12-21T14:42:52.022789Z",
     "shell.execute_reply": "2024-12-21T14:42:52.021853Z",
     "shell.execute_reply.started": "2024-12-21T14:42:52.016171Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Metrics:\n",
    "\n",
    "    @staticmethod\n",
    "    def position_error(label_gt: np.ndarray, label_pr: np.ndarray, step=8, alpha=1.5, e1=5, e2=5):\n",
    "        # gt codes:\n",
    "        # 0 - the ball is not within the image\n",
    "        # 1 - the ball can easily be identified\n",
    "        # 2 - the ball is in the frame, but is not easy to identify\n",
    "        # 3 - the ball is occluded\n",
    "        if label_gt[0] != 0 and label_pr[0] == 0:\n",
    "            return e1\n",
    "        if label_gt[0] == 0 and label_pr[0] != 0:\n",
    "            return e2\n",
    "        dist = math.sqrt((label_gt[1] - label_pr[1]) ** 2 + (label_gt[2] - label_pr[2]) ** 2)\n",
    "        pe = math.floor(dist / step) ** alpha\n",
    "        pe = min(pe, 5)\n",
    "        return pe\n",
    "\n",
    "    @staticmethod\n",
    "    def evaluate_predictions(labels_gt, labels_pr) -> Tuple[List[float], float]:\n",
    "        pe = [Metrics.position_error(labels_gt[i, ...], labels_pr[i, ...]) for i in range(len(labels_gt))]\n",
    "        SIBATRACC = []\n",
    "        for i, _ in enumerate(pe):\n",
    "            SIBATRACC.append(1 - sum(pe[: i + 1]) / ((i + 1) * 5))\n",
    "        SIBATRACC_total = 1 - sum(pe) / (len(labels_gt) * 5)\n",
    "        return SIBATRACC, SIBATRACC_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T14:43:22.098613Z",
     "iopub.status.busy": "2024-12-21T14:43:22.098292Z",
     "iopub.status.idle": "2024-12-21T14:43:22.116123Z",
     "shell.execute_reply": "2024-12-21T14:43:22.115328Z",
     "shell.execute_reply.started": "2024-12-21T14:43:22.098586Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# LBL5 Преобразование данных к YOLO формату\n",
    "def create_yolo_annotations(data_path, output_path):\n",
    "    \"\"\"\n",
    "    Создает YOLO-аннотации для данных о местоположении мяча.\n",
    "    \n",
    "    Args:\n",
    "        data_path (str): Путь к исходным данным.\n",
    "        output_path (str): Путь для сохранения YOLO-аннотаций и изображений.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    for game in os.listdir(data_path):\n",
    "        if 'game' not in game:\n",
    "            continue\n",
    "\n",
    "        game_path = os.path.join(data_path, game)\n",
    "        for clip in os.listdir(game_path):\n",
    "            clip_path = os.path.join(game_path, clip)\n",
    "            labels_path = os.path.join(clip_path, 'labels.csv')\n",
    "\n",
    "            if not os.path.exists(labels_path):\n",
    "                continue\n",
    "\n",
    "            df = pd.read_csv(labels_path)\n",
    "            for _, row in df.iterrows():\n",
    "                visibility = row['visibility']\n",
    "                filename = row['file name']\n",
    "                \n",
    "                # Копирование изображения\n",
    "                image_path = os.path.join(clip_path, filename)\n",
    "                output_image_path = os.path.join(output_path, f\"{game}_{clip}_{filename}\")\n",
    "                shutil.copy(image_path, output_image_path)\n",
    "\n",
    "                # Если мяч отсутствует, создаем пустой файл аннотации\n",
    "                if visibility == 0:\n",
    "                    label_path = os.path.join(output_path, f\"{game}_{clip}_{filename[:4]}.txt\")\n",
    "                    open(label_path, 'w').close()  # Создаем пустой файл\n",
    "                    continue\n",
    "\n",
    "                # Обрабатываем кадры с мячом\n",
    "                x, y = row['x-coordinate'], row['y-coordinate']\n",
    "\n",
    "                # Нормализация координат\n",
    "                image_height, image_width = (720, 1280)\n",
    "                x_center = float(x) / image_width\n",
    "                y_center = float(y) / image_height\n",
    "                width = height = 0.02\n",
    "\n",
    "                # Формирование пути для сохранения аннотаций\n",
    "                label_path = os.path.join(output_path, f\"{game}_{clip}_{filename[:4]}.txt\")\n",
    "                with open(label_path, 'w') as label_file:\n",
    "                    label_file.write(f'{visibility} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n')\n",
    "                    \n",
    "# LBL1 Валидация модели на части обучающей выборки\n",
    "def split_data(input_dir, train_dir, val_dir, val_size=0.2):\n",
    "    \"\"\"\n",
    "    Разделяет данные на тренировочный и валидационный наборы.\n",
    "    \n",
    "    Args:\n",
    "        input_dir (str): Путь к директории с исходными данными.\n",
    "        train_dir (str): Путь для сохранения тренировочного набора.\n",
    "        val_dir (str): Путь для сохранения валидационного набора.\n",
    "        val_size (float): Доля данных для валидационного набора (от 0 до 1).\n",
    "    \"\"\"\n",
    "    os.makedirs(train_dir + '/labels', exist_ok=True)\n",
    "    os.makedirs(train_dir + '/images', exist_ok=True)\n",
    "    os.makedirs(val_dir + '/labels', exist_ok=True)\n",
    "    os.makedirs(val_dir + '/images', exist_ok=True)\n",
    "\n",
    "    all_files = [f for f in os.listdir(input_dir) if f.endswith('.txt')]\n",
    "    random.shuffle(all_files)\n",
    "\n",
    "    split_index = int(len(all_files) * (1 - val_size))\n",
    "    train_files = all_files[:split_index]\n",
    "    val_files = all_files[split_index:]\n",
    "\n",
    "    def move_files(file_list, target_dir):\n",
    "        for file in file_list:\n",
    "            shutil.move(os.path.join(input_dir, file), os.path.join(target_dir + '/labels', file))\n",
    "            shutil.move(os.path.join(input_dir, file.replace('.txt', '.jpg')), os.path.join(target_dir + '/images', file.replace('.txt', '.jpg')))\n",
    "\n",
    "    move_files(train_files, train_dir)\n",
    "    move_files(val_files, val_dir)\n",
    "\n",
    "def create_yaml_file(yaml_path):\n",
    "    \"\"\"\n",
    "    Создает YAML-файл для обучения модели YOLO.\n",
    "    \n",
    "    Args:\n",
    "        train_dir (str): Путь к тренировочному набору данных.\n",
    "        val_dir (str): Путь к валидационному набору данных.\n",
    "        yaml_path (str): Путь для сохранения YAML-файла.\n",
    "    \"\"\"\n",
    "    data = {\n",
    "        'train': 'train/images',\n",
    "        'val': 'val/images',\n",
    "        'nc': 4,  # Количество классов (0, 1, 2, 3)\n",
    "        'names': ['no-ball', 'easy', 'hard', 'occluded']  # Названия классов\n",
    "    }\n",
    "\n",
    "    with open(yaml_path, 'w') as yaml_file:\n",
    "        yaml.dump(data, yaml_file, default_flow_style=False)\n",
    "\n",
    "# Пример использования функций\n",
    "data_path = '/kaggle/input/tennistrackingassignment'\n",
    "output_path = './yolo_annotations/'\n",
    "train_dir = './yolo_annotations/train'\n",
    "val_dir = './yolo_annotations/val'\n",
    "yaml_path = './yolo_annotations/data.yaml'\n",
    "\n",
    "create_yolo_annotations(data_path, output_path)\n",
    "split_data(output_path, train_dir, val_dir)\n",
    "create_yaml_file(yaml_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T14:45:02.645825Z",
     "iopub.status.busy": "2024-12-21T14:45:02.645504Z",
     "iopub.status.idle": "2024-12-21T14:45:02.659420Z",
     "shell.execute_reply": "2024-12-21T14:45:02.658466Z",
     "shell.execute_reply.started": "2024-12-21T14:45:02.645800Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SuperTrackingModel:\n",
    "\n",
    "    def __init__(self, batch_s, stack_s, out_path, downscale):\n",
    "        self.batch_s = batch_s\n",
    "        self.stack_s = stack_s\n",
    "        self.out_path = out_path\n",
    "        self.downscale = downscale\n",
    "        self.original_shape = (720, 1280)\n",
    "        self.model_shape = None\n",
    "        self.model = None\n",
    "\n",
    "    # LBL3 Загрузка модели с какой-то конкретной итерации обучения (если используется итеративное обучение)\n",
    "    def load(self):\n",
    "        # todo: add code for loading model here\n",
    "        model_path = f'tennis_yolo.pt'\n",
    "        file_id = \"1YARi3dU6aIdSPIv7QO64Kt5WJqyuS1wt\"\n",
    "        gdown.download(f\"https://drive.google.com/uc?id={file_id}\", model_path, quiet=False)\n",
    "\n",
    "        self.model = YOLO(model_path)\n",
    "\n",
    "    def predict_on_batch(self, batch: np.ndarray) -> np.ndarray:\n",
    "        # todo: add code for batch mask prediction here\n",
    "        results = self.model(batch, verbose=False)\n",
    "        predicted_boxes = []\n",
    "        for result in results:\n",
    "            if len(result.boxes.cls) == 0:\n",
    "                predicted_boxes.append((0, None))\n",
    "                continue\n",
    "\n",
    "            if self.model_shape is None:\n",
    "                self.model_shape = result.orig_shape\n",
    "                \n",
    "            ball_pred = max(result.boxes, key=lambda result: result.conf)\n",
    "            predicted_boxes.append((ball_pred.cls.cpu().numpy()[0], ball_pred.xyxy[0].cpu().numpy()))\n",
    "            \n",
    "        return predicted_boxes\n",
    "        \n",
    "    def _predict_prob_on_clip(self, clip: np.ndarray) -> np.ndarray:\n",
    "        print('doing predictions')\n",
    "        n_frames = clip.shape[0]\n",
    "\n",
    "        add_frames = 0\n",
    "        while n_frames % self.batch_s != 0:\n",
    "            clip = np.append(clip, [clip[-1]], axis=0)\n",
    "            n_frames += 1\n",
    "            add_frames += 1\n",
    "\n",
    "        batches = []\n",
    "        for i in range(0, n_frames, self.batch_s):\n",
    "            batch = [clip[j] for j in range(i, i + self.batch_s)]\n",
    "            batches.append(batch)\n",
    "\n",
    "        predictions = []\n",
    "        for batch in batches:\n",
    "            pred = self.predict_on_batch(batch)\n",
    "            predictions.extend(pred)\n",
    "            \n",
    "        print('predictions are made')\n",
    "        return predictions\n",
    "\n",
    "    def get_labels_from_prediction(self, predictions: List, upscale_coords: bool) -> np.ndarray:\n",
    "        # todo: get ball coordinates from predicted masks\n",
    "        coords = np.zeros((len(predictions), 3), dtype=np.float32)\n",
    "        \n",
    "        for i, (cls, box) in enumerate(predictions):\n",
    "            if cls == 0:\n",
    "                coords[i] = [0, 0, 0]\n",
    "                continue\n",
    "                \n",
    "            x1 = float(box[0])\n",
    "            y1 = float(box[1])\n",
    "            x2 = float(box[2])\n",
    "            y2 = float(box[3])\n",
    "            x_center = (x1 + x2) / 2\n",
    "            y_center = (y1 + y2) / 2\n",
    "            \n",
    "            if upscale_coords:\n",
    "                scale_x = self.original_shape[1] / self.model_shape[1]\n",
    "                scale_y = self.original_shape[0] / self.model_shape[0]\n",
    "                x_center *= scale_x\n",
    "                y_center *= scale_y\n",
    "            coords[i] = [cls, x_center, y_center]\n",
    "        \n",
    "        return coords\n",
    "\n",
    "    def predict(self, clip: np.ndarray, upscale_coords=True) -> tuple[np.ndarray, np.ndarray]:\n",
    "        prob_pr = self._predict_prob_on_clip(clip)\n",
    "        labels_pr = self.get_labels_from_prediction(prob_pr, upscale_coords)\n",
    "        return labels_pr, prob_pr\n",
    "\n",
    "    def test(self, data_path: Path, games: List[int], do_visualization=False, test_name='test'):\n",
    "        game_clip_pairs = get_game_clip_pairs(data_path, games)\n",
    "        SIBATRACC_vals = []\n",
    "        for game, clip in game_clip_pairs:\n",
    "            data = load_clip_data(data_path, game, clip, downscale=self.downscale)\n",
    "            if do_visualization:\n",
    "                data_full = load_clip_data(data_path, game, clip, downscale=False) if self.downscale else data\n",
    "            labels_gt = load_clip_labels(data_path, game, clip, downscale=False)\n",
    "            labels_pr, prob_pr = self.predict(data)\n",
    "            SIBATRACC_per_frame, SIBATRACC_total = Metrics.evaluate_predictions(labels_gt, labels_pr)\n",
    "            SIBATRACC_vals.append(SIBATRACC_total)\n",
    "            if do_visualization:\n",
    "                visualize_prediction(data_full, labels_pr, self.out_path, f'{test_name}_g{game}_c{clip}', SIBATRACC_per_frame)\n",
    "                visualize_prob(data, prob_pr, self.out_path, f'{test_name}_g{game}_c{clip}')\n",
    "                del data_full\n",
    "            del data, labels_gt, labels_pr, prob_pr\n",
    "            gc.collect()\n",
    "        SIBATRACC_final = sum(SIBATRACC_vals) / len(SIBATRACC_vals)\n",
    "        return SIBATRACC_final\n",
    "\n",
    "    def train(self):\n",
    "        # todo: implement model training here\n",
    "        if self.model is None:\n",
    "            self.model = YOLO('yolo11l.pt')\n",
    "\n",
    "        # LBL2 Автоматическое сохранение модели при обучении\n",
    "        # LBL4 Вывод различных показателей в процессе обучения (например, значение функции потерь на каждой эпохе)\n",
    "        self.model.train(\n",
    "            data='/kaggle/working/yolo_annotations/data.yaml',\n",
    "            epochs=10,\n",
    "            batch=10,\n",
    "            imgsz=640,\n",
    "            workers=4,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.52 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.47 🚀 Python-3.11.5 torch-2.5.1+cu124 CUDA:0 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:1 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:2 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:3 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:4 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:5 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:6 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:7 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11l.pt, data=/opt/notebooks/sports-tracking-tystem/yolo_annotations/data.yaml, epochs=10, time=None, patience=100, batch=72, imgsz=640, save=True, save_period=-1, cache=False, device=[0,1,2,3,4,5,6,7], workers=32, project=None, name=train20, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/opt/notebooks/sports-tracking-tystem/runs/detect/train20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1734779623.452766 4037372 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1734779623.458076 4037372 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=4\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  2    173824  ultralytics.nn.modules.block.C3k2            [128, 256, 2, True, 0.25]     \n",
      "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  4                  -1  2    691712  ultralytics.nn.modules.block.C3k2            [256, 512, 2, True, 0.25]     \n",
      "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  6                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  2   1455616  ultralytics.nn.modules.block.C2PSA           [512, 512, 2]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  2    756736  ultralytics.nn.modules.block.C3k2            [1024, 256, 2, True]          \n",
      " 17                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  2   2365440  ultralytics.nn.modules.block.C3k2            [768, 512, 2, True]           \n",
      " 20                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
      " 23        [16, 19, 22]  1   1414108  ultralytics.nn.modules.head.Detect           [4, [256, 512, 512]]          \n",
      "YOLO11l summary: 631 layers, 25,313,564 parameters, 25,313,548 gradients, 87.3 GFLOPs\n",
      "\n",
      "Transferred 1009/1015 items from pretrained weights\n",
      "\u001b[34m\u001b[1mDDP:\u001b[0m debug command /opt/notebooks/sports-tracking-tystem/.venv/bin/python -m torch.distributed.run --nproc_per_node 8 --master_port 40559 /root/.config/Ultralytics/DDP/_temp_8o7muagt140334492132368.py\n",
      "Ultralytics 8.3.47 🚀 Python-3.11.5 torch-2.5.1+cu124 CUDA:0 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:1 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:2 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:3 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:4 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:5 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:6 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:7 (NVIDIA A100-SXM4-80GB, 81158MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1734779634.526559 4037475 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1734779634.533932 4037475 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /opt/notebooks/sports-tracking-tystem/runs/detect/train20', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=4\n",
      "Transferred 1009/1015 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /opt/notebooks/sports-tracking-tystem/yolo_annotations/train/labels... 11436 images, 564 backgrounds, 0 corrupt: 100%|██████████| 11436/11436 [00:06<00:00, 1655.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /opt/notebooks/sports-tracking-tystem/yolo_annotations/train/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /opt/notebooks/sports-tracking-tystem/yolo_annotations/val/labels... 4293 images, 216 backgrounds, 0 corrupt: 100%|██████████| 4293/4293 [00:02<00:00, 1568.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /opt/notebooks/sports-tracking-tystem/yolo_annotations/val/labels.cache\n",
      "Plotting labels to /opt/notebooks/sports-tracking-tystem/runs/detect/train20/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 167 weight(decay=0.0), 174 weight(decay=0.0005625000000000001), 173 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 640 train, 640 val\n",
      "Using 128 dataloader workers\n",
      "Logging results to \u001b[1m/opt/notebooks/sports-tracking-tystem/runs/detect/train20\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10       6.8G      1.795      4.481      1.187          7        640: 100%|██████████| 159/159 [00:45<00:00,  3.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 239/239 [00:17<00:00, 13.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4293       4077      0.336    0.00451   0.000593   9.44e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10       6.7G      1.174      1.119     0.9241          7        640: 100%|██████████| 159/159 [00:43<00:00,  3.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 239/239 [00:18<00:00, 13.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4293       4077      0.958      0.261       0.31      0.203\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10       6.7G      1.114      1.062     0.9027          8        640: 100%|██████████| 159/159 [00:43<00:00,  3.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 239/239 [00:18<00:00, 13.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4293       4077      0.933      0.265       0.31      0.171\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10       6.7G      1.053     0.9764     0.8978          8        640: 100%|██████████| 159/159 [00:43<00:00,  3.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 239/239 [00:17<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4293       4077      0.641      0.328      0.326      0.134\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10       6.7G     0.9717     0.8283     0.8703          7        640: 100%|██████████| 159/159 [00:43<00:00,  3.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 239/239 [00:17<00:00, 13.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4293       4077      0.706      0.357      0.375     0.0565\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10       6.7G     0.9319     0.7665     0.8561          8        640: 100%|██████████| 159/159 [00:43<00:00,  3.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 239/239 [00:17<00:00, 13.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4293       4077      0.458      0.488      0.446      0.116\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10       6.7G     0.8707     0.7151     0.8542          8        640: 100%|██████████| 159/159 [00:43<00:00,  3.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 239/239 [00:17<00:00, 13.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4293       4077      0.482        0.5      0.444      0.119\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10       6.7G      0.846     0.6745     0.8526          8        640: 100%|██████████| 159/159 [00:43<00:00,  3.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 239/239 [00:17<00:00, 13.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4293       4077      0.562      0.543      0.505      0.145\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10       6.7G     0.8389      0.658     0.8415          7        640: 100%|██████████| 159/159 [00:43<00:00,  3.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 239/239 [00:17<00:00, 13.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4293       4077      0.621      0.538      0.521      0.197\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10       6.7G     0.7777     0.5911     0.8333          7        640: 100%|██████████| 159/159 [00:43<00:00,  3.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 239/239 [00:17<00:00, 13.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4293       4077      0.697      0.565      0.563        0.2\n",
      "\n",
      "10 epochs completed in 0.177 hours.\n",
      "Optimizer stripped from /opt/notebooks/sports-tracking-tystem/runs/detect/train20/weights/last.pt, 51.2MB\n",
      "Optimizer stripped from /opt/notebooks/sports-tracking-tystem/runs/detect/train20/weights/best.pt, 51.2MB\n",
      "\n",
      "Validating /opt/notebooks/sports-tracking-tystem/runs/detect/train20/weights/best.pt...\n",
      "Ultralytics 8.3.47 🚀 Python-3.11.5 torch-2.5.1+cu124 CUDA:0 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:1 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:2 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:3 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:4 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:5 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:6 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:7 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "YOLO11l summary (fused): 464 layers, 25,282,396 parameters, 0 gradients, 86.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 239/239 [00:17<00:00, 13.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4293       4077      0.696      0.565      0.563        0.2\n",
      "                  easy       3695       3695      0.885      0.961      0.977      0.369\n",
      "                  hard        362        362      0.508      0.384      0.394      0.129\n",
      "              occluded         20         20      0.696       0.35      0.319      0.102\n",
      "Speed: 0.1ms preprocess, 1.5ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1m/opt/notebooks/sports-tracking-tystem/runs/detect/train20\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "output_path = prepare_experiment(Path('/kaggle/working'))\n",
    "model = CustomTrackingModel(10, 10, out_path=output_path, downscale=True)\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T14:46:40.258981Z",
     "iopub.status.busy": "2024-12-21T14:46:40.258535Z",
     "iopub.status.idle": "2024-12-21T14:48:43.737097Z",
     "shell.execute_reply": "2024-12-21T14:48:43.736184Z",
     "shell.execute_reply.started": "2024-12-21T14:46:40.258941Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1YARi3dU6aIdSPIv7QO64Kt5WJqyuS1wt\n",
      "From (redirected): https://drive.google.com/uc?id=1YARi3dU6aIdSPIv7QO64Kt5WJqyuS1wt&confirm=t&uuid=71f9abec-688e-47a0-b54a-31331c2d1203\n",
      "To: /kaggle/working/tennis_yolo.pt\n",
      "100%|██████████| 51.2M/51.2M [00:00<00:00, 94.2MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading clip data (game 1, clip 1) downscaled\n",
      "loading clip labels (game 1, clip 1)\n",
      "doing predictions\n",
      "predictions are made\n",
      "loading clip data (game 1, clip 2) downscaled\n",
      "loading clip labels (game 1, clip 2)\n",
      "doing predictions\n",
      "predictions are made\n",
      "loading clip data (game 1, clip 3) downscaled\n",
      "loading clip labels (game 1, clip 3)\n",
      "doing predictions\n",
      "predictions are made\n",
      "loading clip data (game 1, clip 4) downscaled\n",
      "loading clip labels (game 1, clip 4)\n",
      "doing predictions\n",
      "predictions are made\n",
      "loading clip data (game 1, clip 5) downscaled\n",
      "loading clip labels (game 1, clip 5)\n",
      "doing predictions\n",
      "predictions are made\n",
      "loading clip data (game 1, clip 6) downscaled\n",
      "loading clip labels (game 1, clip 6)\n",
      "doing predictions\n",
      "predictions are made\n",
      "loading clip data (game 1, clip 7) downscaled\n",
      "loading clip labels (game 1, clip 7)\n",
      "doing predictions\n",
      "predictions are made\n",
      "loading clip data (game 1, clip 8) downscaled\n",
      "loading clip labels (game 1, clip 8)\n",
      "doing predictions\n",
      "predictions are made\n",
      "loading clip data (game 2, clip 1) downscaled\n",
      "loading clip labels (game 2, clip 1)\n",
      "doing predictions\n",
      "predictions are made\n",
      "loading clip data (game 2, clip 2) downscaled\n",
      "loading clip labels (game 2, clip 2)\n",
      "doing predictions\n",
      "predictions are made\n",
      "loading clip data (game 2, clip 3) downscaled\n",
      "loading clip labels (game 2, clip 3)\n",
      "doing predictions\n",
      "predictions are made\n",
      "loading clip data (game 2, clip 4) downscaled\n",
      "loading clip labels (game 2, clip 4)\n",
      "doing predictions\n",
      "predictions are made\n",
      "loading clip data (game 2, clip 5) downscaled\n",
      "loading clip labels (game 2, clip 5)\n",
      "doing predictions\n",
      "predictions are made\n",
      "loading clip data (game 2, clip 6) downscaled\n",
      "loading clip labels (game 2, clip 6)\n",
      "doing predictions\n",
      "predictions are made\n",
      "loading clip data (game 2, clip 7) downscaled\n",
      "loading clip labels (game 2, clip 7)\n",
      "doing predictions\n",
      "predictions are made\n",
      "loading clip data (game 2, clip 8) downscaled\n",
      "loading clip labels (game 2, clip 8)\n",
      "doing predictions\n",
      "predictions are made\n",
      "loading clip data (game 2, clip 9) downscaled\n",
      "loading clip labels (game 2, clip 9)\n",
      "doing predictions\n",
      "predictions are made\n",
      "SiBaTrAcc final value: 0.8310512723898543\n"
     ]
    }
   ],
   "source": [
    "output_path = prepare_experiment(Path('/kaggle/working'))\n",
    "new_model = SuperTrackingModel(10, 10, out_path=output_path, downscale=True)\n",
    "new_model.load()\n",
    "sibatracc_final = new_model.test(Path('/kaggle/input/tennistrackingassignment/test'), [1,2], do_visualization=False, test_name='test')\n",
    "print(f'SiBaTrAcc final value: {sibatracc_final}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1250524,
     "sourceId": 2085688,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
